- 大模型的攻防战：
- 常见的攻击方式：
	- DDos攻击（分布式拒绝服务）：系统超负荷，大量异常注册
		- ->限制境外用户注册，禁止泄露的API，扩容服务器。
		- 建立“双重安全机制”——“DDoS防护全覆盖 + 重大活动保障”。
		- 在网络层（第4层）加强流量过滤，还在应用层（第7层）进行深度防护，防止攻击通过大量流量压垮系统或恶意请求入侵应用。结合国内腾讯云与海外节点，提升了防护带宽，加强联防机制，确保业务持续可用。
	- 代码开源：训练的敏感数据、模型权重、代码漏洞和依赖。
		- 建立了“开源准出审计 - 漏洞管理 - 情报监控”三位一体的防护体系。
		- 覆盖了从开源项目发布前的安全审查，到正式开源后的全生命周期管理。确保每个开源项目在发布前都经过严格的安全审查，并对外部安全事件进行实时监控，将潜在风险收敛到可控范围内，最大程度减少开源带来的安全隐患。
	- Prompt攻击：输入诱导模型生成不当内容获取后台敏感数据与系统权限，或者通过AI分析意图生成并且注入恶意代码然后窃取用户文件、模型文件、训练数据、其他业务的服务器。
		- 对抗样本训练；专门的Prompt检测系统；沙箱加固（对模型底层架构采用了双层沙箱加固，将所有模型输出限制在虚拟环境中，确保即使被恶意利用，攻击者也无法直接影响生产环境或窃取敏感数据。）
		-
	- 内部人员滥用职权或泄露敏感信息
		- 审计和监控，基线建模，定期演练，安全培训
	- 供应链风险：攻击者伪装成合法组件利用漏洞植入恶意代码或者执行恶意操作（不论是开源社区还是商业团队的产品都可能收到供应链攻击，需要对三方组件加强管理）
		- 严格的引入与审计流程：基于SDL框架建立第三方组件准入控制矩阵，实施源码级SCA扫描、License合规审查、CVE关联分析三重过滤机制。通过威胁情报订阅与EPSS漏洞可利用性预测模型，构建动态风险画像系统，在发布流程中添加质量红线检查点，**实现高危组件100%阻断、关键组件安全基线达标率100%。**
		- 实时监控与快速响应：部署供应链攻击感知系统，动态跟踪组件依赖的更新状态。针对0day漏洞（如Log4j2）及恶意代码投毒（如Rspack投毒），系统会立即发出警告，并通过自动化编排功能，在小时级别内实现相关组件的禁用。
	-
-
-
- 关于 **大模型业务流程** 及其 **安全风险点** 的概览，分为 **数据、训练、推理、应用/场景** 四个主要阶段，涉及 **大模型训练平台、模型开源、ToB/ToC应用** 三个模块。
- 1. 大模型训练平台（数据 → 训练）
  涉及数据的准备、训练和评估。
	- (1) 数据存储
		- 作用：存储用于训练大模型的数据，包括文本、图片、音频等。
		- 风险：数据存储涉及 **数据泄露** 或 **违规数据存储** 问题，尤其是敏感数据。
	- (2) 数据流转
		- 作用：从存储中提取数据，进行数据清洗，确保数据质量。
		- 风险：数据流转可能涉及 **数据滥用** 或 **非授权访问**，需要严格权限控制。
	- (3) 数据使用
		- 作用：处理后的数据被用于训练大模型，包括特征提取、数据增强等。
		- 风险：
			- 高价值数据（隐私/安全）可能存在数据滥用风险，例如未经授权使用用户数据。
			- 如果数据来源不合规，训练出的模型可能携带违规信息，导致下游应用产生风险。
	- (4) 模型训练
		- 作用：使用数据对大模型进行训练，优化参数，使其具备语言理解、生成等能力。
		- 风险：训练数据如果包含 **偏见** 或 **虚假信息**，可能导致模型输出有问题。
	- (5) 模型调试
		- 作用：对训练好的模型进行调试，调整参数，改进表现。
		- 风险：不安全的调试环境可能导致 **数据泄露** 或 **模型窃取**。
	- (6) 模型评估
		- 作用：评估训练后模型的效果，测试其在不同任务上的表现。
		- 风险：如果评估标准不严格，可能导致模型存在安全漏洞。
- 2. 模型开源（推理）
  这是大模型的 **推理阶段**，主要涉及模型的开放与使用。
	- (1) 模型
		- 作用：经过训练的模型可以用于推理任务，如对话、生成文本等。
		- 风险：开源模型可能被恶意使用，或者模型本身存在漏洞（如 **对抗攻击**）。
	- (2) 数据
		- 作用：模型推理时仍然可能依赖一些输入数据，例如用户的查询。
		- 风险：推理时如果输入 **恶意数据**，可能导致模型输出错误或敏感信息泄露。
	- (3) 镜像
		- 作用：模型、代码、环境可能被打包成镜像，方便部署。
		- 风险：如果镜像安全性不好，可能被 **植入后门** 或 **篡改**，导致供应链攻击。
	- (4) 代码
		- 作用：开源代码用于推理时，开发者可以二次开发、优化。
		- 风险：代码安全性如果不足，可能被黑客利用，执行恶意操作。
	- (5) 体验门户
		- 作用：提供一个用户可以体验模型推理结果的平台（如 AI 聊天机器人）。
		- 风险：
			- 内部数据泄露（如推理时模型暴露训练数据）。
			- 推理结果泄露（如敏感对话被第三方监听）。
- 3. ToB / ToC 应用（应用/场景）
  这是大模型的 **应用阶段**，涉及实际产品和业务。
	- (1) 对话/Prompt 服务
		- 作用：基于大模型的对话系统，允许用户输入 Prompt（提示词）来生成文本。
		- 风险：
			- 如果 Prompt 设计不当，可能导致模型生成不良内容（如虚假信息）。
			- 攻击者可以利用 **提示词注入（Prompt Injection）** 来绕过安全机制。
	- (2) 模型
		- 作用：模型在应用层继续提供推理服务，如智能助手、AI 生成文本等。
		- 风险：如果应用端没有过滤掉不当输入，可能导致 **内容合规风险**。
	- (3) 传统推理服务
		- 作用：模型可以作为 API 或插件，为其他应用提供推理支持。
		- 风险：接口可能被滥用，导致 **未授权访问** 或 **数据滥用**。
	- (4) 插件
		- 作用：模型的能力可以被集成到插件中，用于特定任务，如 AI 翻译、写作助手等。
		- 风险：插件如果没有严格的权限管理，可能被恶意利用。
	- ⚠ 身份伪造 & 应用层合规
		- 风险1（身份伪造）：对话、插件等功能如果没有严格的身份验证，可能会被滥用（如黑客伪造身份绕过权限）。
		- 风险2（应用层合规）：应用层需要严格监控，防止不合规内容的传播。
-
-
- 总结
  📌 大模型业务的完整流程关键的 **安全风险**：
- 数据阶段：数据隐私、数据滥用
- 训练阶段：数据安全、模型偏见
- 推理阶段：模型安全、数据泄露
- 应用阶段：身份伪造、提示词攻击、内容合规
-
-
- # 🥱网络安全
- 名词：渗透测试，靶场，永恒之蓝，扫端口找脆弱性，virus total木马哈希nmap，cisp，burpsiite,IDA Pro反编译
-
-
-